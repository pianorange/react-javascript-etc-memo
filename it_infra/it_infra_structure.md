## Chapter 1 인프라 아키택쳐를 살펴보자

인프라 = IT기반이 되는 것.  
아키텍쳐 = 구조

모든곳에서 공통으로 사용가능한 아키텍쳐가 있을까?  
No!  
아키텍쳐나 설계 요소에는 반드시 장점과 단점 공존.  
가장 큰 제약 : 시스템 도입 비용  
ex) 100만명 사용하는 시스템과 10명 사용하는 시스템 예산 차이 큼

### 1.2 집약형과 분할형 아키텍쳐

IT 인프라는 컴퓨터로 구성되며, 집약형과 분할형 존재.

#### 1.2.1 집약형 아키텍쳐

옛날 에는 대형 컴퓨터 이용 모든 업무 처리하는 범용장비가 사용됨  
모든 처리를 한대로 하기 때문에 장비 고장 등으로 업무 멈추지 않도록 고민이 필요.  
복수의 서로 다른 업무 처리 동시 실행 하도록 유한 리소스 관리 필요.  
한대의 컴퓨터지만 안에 여러 프로세스가 존재, 하드웨어 일부 고장에도 작동 필요.

(기간 시스템, 호스트, 메인프레임 등으로도 불림)  
장점: 한대의 대형 컴퓨터. 구성이 간단하다, 리소스관리, 이중화에 의해 안정성 높고 고성능.
단점: 도입비용, 유지비용 크다. 확장성에 한계가 있다.

#### 1.2.2 분할형 아키텍쳐

여러 대의 컴퓨터를 조합해서 하나의 시스템을 구축하는 구조.  
-> 대형 컴퓨터가 했던 처리 다수 소형 컴퓨터 분할 처리.  
서버 분할 일반적인 방식은 수직형과 수평형 2가지 존재.  
수직형: 각 서버별로 다른 역할 담당  
수평형: 각 서버가 같은 역할 담당

장점:

1. 대형컴퓨터는 매우 고가. 저가 장비 이용 전체적인 비용 절감 가능
2. 안정성은 대형 컴퓨터에 못미치지만, 여러 대의 컴퓨터 이용 한 대가 고장 나도 안정성 담보 가능
3. 서버 대수 늘릴 수 있어서 확장성 높다.

단점:

1. 대수가 늘어나면 관리 구조 복잡해짐
2. 한 대가 망가지면 영향 범위 최소화 위한 구조를 검토해야 함

#### 물리 서버와 논리 서버의 차이

분할형 아키텍쳐 이용되는 컴퓨터를 서버라고 함.  
-> 서버는 컴퓨터 자체(하드웨어, 물리적인 의미)를 칭하기도 하고 컴퓨터에서 동작하는 소프트웨어(DB서버, 웹 서버, 논리적 의미)를 칭하기도 함.  
서버의 본래 의미: 특정 역할에 특화된 것

### 1.3 수직 분할형 아키텍쳐

서버별로 다른 역할 담당  
특정 서버 측면에서 봣을 때 역할에 따라 '위'또는 '아래'계층으로 나뉨

#### 1.3.1 클라이언트-서버형 아키텍쳐

클라이언트-서버형은 수직분할형의 한 예이다.  
물리서버는 애플리케이션, 미들웨어, 데이터베이스 등 소프트웨어를 물리서버 상에서 운영  
클라이언트(또는 단말)은 서버에 접속해서 서비스 이용하는 형태

클라이언트-서버형의 특징

- 클라이언트 측에 전용 소프트웨어 설치 (ex 주식 판매 프로그램)
  ->그래프표시나 주가 흐름 분석은 PC에서 하고 주가 데이터 취득은 서버에서  
  ->처리는 각각의 클라이언트 단말에 맡기고 서버는 데이터 입출력만 하면 되기 때문에 처리당 부하량을 낮출 수 있다.  
  -> 부하가 낮은 만큼 소수의 서버로 다수의 클라이언트 처리 가능

클라이언트-서버형의 단점  
업무 애플리케이션 갱신 시마다 클라이언트 측 소프트웨어도 업데이트 해야한다.  
이용자 측에서 불편, 무시하고 넘어가는 경우도 많아 시스템 위험 요소가 될 수 있다.

- 클라이언트 측의 소프트 웨어 정기 업데이트 필요
- 서버 확장성에 한계 발생 가능성

#### 1.3.2 3계층형 아키텍쳐

클라이언트-서버의 발전된 형태  
-> 클라이언트와 서버만 나뉘어 있었기 때문에 서버에 너무 많은 부하가 집중됨  
-> 이에 서버의 역할을 나눠 부하 집중문제를 해결함  
-> 웹 브라우저를 통한 접속(프레젠테이션 계층 있으므로)이므로 클라이언트 업데이트 필요 X

<3계층의 구성>

1. 프레젠테이션 계층

- 사용자 입력을 받음
- 웹 프라우저 화면 표시

2. 애플리케이션 계층

- 사용자 요청에 따라 업무처리

3. 데이터 계층

- 애플리케이션 계층의 요청에 따라 데이터 입출력

웹브라우저 통해 시스탬에 접속(사용자)  
->사용자가 웹 브라우저에 입력하는 화면은 프레젠테이션 계층의 웹 서버에 먼저 전달 됨  
-> 웹 서버는 그 요청을 애플리케이션 계층의 AP(application)서버에 전달  
-> AP서버는 데이텨 계층의 데이터 베이스에 데이터 요청

장점

- 서버 부하 집중 개선
- 클라이언트 단말의 정기 업데이트 불필요
- 처리반환에 의한 서버 부하 저감

단점

- 구조가 클라이언트-서버 구성보다 복잡하다.

##### Memo

웹소켓 : 기존 웹에서는 브라우저가 웹 서버에 요청을 보내서 그것을 받아 처리하는 구조  
-> 웹소캣은 요청이 없어도 웹 서버가 브라우저에 데이터를 전달(푸시)할 수 있다.  
이를 통해 브라우저가 더 많은 것을 실행할 수 있는 형태로 진화하고 있다.

### 1.4 수평 분할형 아키텍쳐

용도가 같은 서버를 늘려나가는 방식  
서버 대수 늘어나면 한 대가 시스템에 주는 영향력 낮아져 안정성 향상

- 수직 분할형과 수평 분할형은 배타적인 관계가 아니다 (대부분 두가지 방식 혼재)

#### 1.4.1 단순 수평 분할형 아키텍쳐

같은 기능 가진 복수의 시스템으로 단순 분할.  
sharding(샤딩), partitioning(파티셔닝)이라고도 부름 .
ex ) 3계층 레이어로 구성된 동일한 구성의 어플리케이션을 서울지사와 부산지사로 나눠 구성.  
-> 필요에 따라 서울지사에 접속해 데이터를 확인하거나 부산지사에 접속해 데이터 확인
거리상으로 멀리 떨어진 시스템에 자주 이용됨.  
 공장처럼 각 거점이 완전히 독립된 운영 하거나, 많은 사용자가 있는 SNS 웹 서비스에서 사용자 ID기준으로 서버를 분할(sharding)하기도 한다.

장점

1. 시스템 둘로 분할됨으로써 전체 처리성능 나눈만큼 향상(부하가 한곳으로 집중되지 않으니까)
2. 각각 독립된 시스템이므로 한쪽에 장애가 발생해도 상호 시스템간 영향 X

단점

1. 업데이트시마다 매번 양쪽시스템을 수정해야함
2. 데이터가 일원화 되어있지 않아 양쪽 데이터 동시 사용 불가
3. 처리량이 균등하게 분할돼 있지 않으면 서버별 처리량에 치우침 발생 가능성

#### 1.4.2 공유형 아키텍쳐

일반 기업 시스템이라면 완전 분리된 애플리케이션 이용하는 경우 드물다.  
공유형에서는 단순 분할형과 달리 일부 계층에서 상호 접속이 이루어짐.  
ex ) 단순 수평 분할형에서 DB데이터 동기화

장점

1. 수평으로 서버 늘리기 때문에 확장성향상
2. 분할한 시스템이 서로 다른 시스템의 데이터 참조가능

단점

- 분할한 시스템 간 독립성 낮아짐
- 공유한 계층의 확장성 낮아짐

##### Memo 가상화

집약형 : 대형 컴퓨터의 높은 비용이 문제, 확장성에 문제
분할형: 안정성문제, 구성이 복잡해짐

<b>가상화</b>: 집약형, 분할형 양쪽 장점을 취하는 접근법
ex) 물리서버 2대 준비, 가상화 기능으로 여러대 가상 서버로 분할.  
->물리서버 이중화 해서 한 대가 망가져도 계속해서 운영가능
-> 리소스의 확장성 보장 가능하며,가상서버 여러대로 처리량을 늘릴 수 있다.

## 1.5 지리 분할형 아키텍쳐

특정 목적에 맞춰 수직, 수평 분할 아키텍쳐 조합한 구성

### 1.5.1 스탠바이형 아키택쳐

스탠바이 구성, 액시브-스탠바이 구성, HA(High availability)구성 이라고도 부름.

물리 서버 최소 두대 준비 한대 고장나면 가동중인 소프트웨어를 다른 한대로 옮겨서 운영하는 방식  
이때 소프트웨어 재시작 자동으로 하는 구조 페일오버(failover)라고 함

단점

- 물리 서버 고장에 대처 가능하지만 보통 대는 페일오버 대상 서버(스탠바이)가 놀고 있는 상태가 되기 때문에 리소스 낭비 발생

->이 때문에 스탠바이 따로 두지 않고, 양쪽 서버 동시에 교차이용하다 한쪽이 고장나면 다른 한쪽으로 트래픽 집중시키는 방식 사용하는 경우도 많다.  
-> 가상화 서버 이용시 서버상의 소프트웨어 뿐만 아니라 다른 물리 서버에 페일오버 하는 방식도 선택지가 될 수 있음.

### 1.5.3 클라우드형 아키텍쳐

사용자 쪽에서 보면 일반 서버처럼 동작하지만, 가상화돼 있어서 사용자는 어느 물리서버에서 동작하고 있는지 모름  
3계층형 시스템의 일부 또는 전부가 클라우드 서비스 제공자가 보유한 물리서버에서 동작  
-> 어떤 계층을 클라우드 상에 배치하냐에 따라 명칭이 다르다.

1. SaaS (Software as a Service) : 서버뿐만 아니라 애플리케이션 포함한 업무 시스템을 클라우드 서비스 회사가 제공.
   -> 사용자는 인프라를 의식할 필요가 없다.
   ex) Yahoo메일, Gmail

2. PaaS, IaaS, DBaaS: 일반적인 3계층형 시스템 구성하는 서버의 일부 혹은 전부를 클라우드 상의 리소스로 대체  
   -> 이 경우 인프라 설계자는 인프라를 의식해서 장단점 고려한 설계 해야함  
   ex) 물리서버 구입에 비해 비용 낮고 바로 사용 가능하지만, 보안문제, 클라우드 서비스 제공자의 네트워크 연장 문제등 있을 수 있다.

양쪽의 장점만을 가져와서 <b>사내 클라우드</b> 구성하는 경우도 많음.

# Chapter 2. 서버를 열어보자

#### 2.1.2 서버 내부 구성

서버의 구조는 기본적으로 PC와 같다.

- CPU(Centeral processing unit)와 메모리는 물리적으로 직접 연결
- CPU중심으로 생각하면 HDD나 네트워크 인터페이스는 메모리에 비해 멀리 있다.

### 2.2 CPU

중앙 연산장치.  
멀티코어화가 진행되고 있으며 코어는 각자 독립된 처리수행.  
명령이나 데이터는 기억장치에 있지만,
웹서버나 DB의 프로세스, 사용자(마우스 키보드 통한 조작)-> OS -> CPU  
-> 이때 마우스, 키보드 하는 처리를 끼어들기(interrupt) 처리라고 부름.

### 2.3 Memory

CPU 옆에 위치하는 기억영역.  
저장된 데이터는 휘발성이지만, 액세스가 매우 빠르다.

메모리 CPU간 통신은 메모리컨트롤러 경유해서 이뤄지며,  
이때 통신이 이뤄지는 데이터 경로를 '채널'이라고 한다.

CPU자체도 레지스터나 1차(L1)/2차(L2)라고 불리는 메모리를 갖고 있다.  
->메모리보다도 빠르지만 용량이 매우작다  
->빈번하게 사용하는 데이터, 명령순서대로 CPU에 가까운 쪽에 캐시된다

- L1캐시(초고속 캐시, 각 코어 전용)
- L2캐시(고속 캐시, 각 코어전용)
- L3캐시(준고속캐시, CPU전체가 공유)

#### 메모리 영역이 몇개나 존재하는 이유

메모리를 이용하려면 메모리 컨트롤러를 경유해서 CPU 밖으로 나가야 함  
-> 이런 처리지연(latency) 피하기 위해서 가장 자주 사용하는 명령/데이터를 코어 가까운 곳에 배치

#### CPU 캐시메모리 영역이 여러 단계인 이유

액세스 속도 때문.  
일반적으로 캐시 메모리가 커질수록 액세스 속도가 느려지므로, 여러단계로 배치해서  
가능한 많은 캐시를 확보.

## I/O 장치

### 2.4.1 하드드라이브

기록영역
장기저장목정의 데이터 저장 장소

- HDD: 메모리와 달리 전기가 없어도 데이터가 사라지지 않음.  
  -> CD/DVD와 같은 구조. 회전판에 데이터 기록됨.  
  -> 회전 구조때문에 속도가 물리 법칙에 좌우되며, 메모리처럼 순식간에 액세스 불가

- SSD(Solid State Disk): 물리적인 회전요소 사용 않는 디스크
  메모리와 같이 반도체로 만들어 졌지만 전기가 없어도 데이터 사라지지 않음.  
  -> 메모리와 기억장치 간 속도 차이가 거의 없어지고 있다.

- 스토리지(Storage 저장소): HDD가 많이 탑재되어있는 저장소  
  I/O의 서브 시스템이라고도 불리는 장치, 내부에는 CPU와 캐시가 존재하고 수많은 HDD 와 여러 기능 탑재.
  -> 서버와 I/O시 HDD가 직접 데이터 교환 X 저장소 캐시를 통해한다.
  -> 저장소 캐시 이용방법은 CPU캐사와 동일
  -> 메모리처럼 고속으로 I/O 가 가능한 하드웨어라는 정도로 알아둘 것.

### 2.4.2 네트워크 인터페이스

서버와 외부장비를 연결하기 위한 외부접속용 인터페이스  
LAN, SAN등 어댑터를 통해 연결됨  
참고: CPU관점에서는 HDD와 네트워크둘다 I/O핸들러 라는 컨트롤러를 거쳐  
통신한다는 점에서 외부I/O라는 의미에서 동일하다.

### 2.4.3 I/O 제어

IOH(I/O Handler): CPU에 물려있는 I/O핸들러. 예전에는 메모리관련 I/O처리가 주된 임무였으나, CPU로 그 임무가 옮겨가고, PCI Express등 고속ㅊ러리가 필요한 I/O 담당

ICH(I/O Controller): USB,CD,DVD등과 같이 고속처리가 필요없는 I/O제어를 담당.IOH간 데이터 전송 제어도 한다.

### 2.5 버스

서버 내부에 있는 컴포넌트들을 서로 연결시키는 회선.
버스에서 중요한건 어느정도의 데이터 전송 가능한지 의미하는 대역이 중요  
-> 한번ㅋ에 데이터 보낼수 있는 데이터의 폭(전송폭) 1초에 전송할 수 있는 횟수

- 버스대역: 메모리와 CPU는 대량의 데이터 교환을 필요로 하므로 CPU쪽 버스대역이 가장 크다. 즉 1초당 전송량이 크다.  
  반대로 USB포트는 60MB/S전송 능력을 가진 규격으로 저속이기 때문에 ICH(I/O Controller)앞에 배치해도 문제가 없다.

버스 흐름에서 중요한 것은 CPU와 장치사이 병목현상이 없어야 한다는 것이다.  
외부장치 연결 시의 버스 대역에 관한부분 주의

> TODO PCI Express 2.0 알아보려면 알아볼것

### 2.6 정리

HDD 부터 CPU까지 데이터가 도달하는 여정  
CPU코어 <->레지스터<->L1~3캐시<->메모리<->IOH(IO Handler)<->HBA<->저장소캐시<->HDD

- CPU에 가까울 수록 고속이고 멀수록 대용량인 것을 알 수 있다.

# Chapter3 3계층형 시스템을 살펴보자

## 3.1 3계층형 시스템의 구성도

- 각 계층의 서버는 스위치를 통해 연결되어있다
  ![3stage arch](./it_infra_img/it_infra_chapter3.jpg)

## 3.2 주요개념

- OS를 이해하려면 프로세스와 스레드, 커널을 이해해야 함

### 3.2.1 프로세스와 스레드

#### 프로세스가 시작되는 흐름

1. 특정 프로그램은 서버 내부의 디스크에 설치된다.
2. 시작 의뢰 있으면 '커널'이 프로세스를 작성하고 요청 분량만큼만 메모리 공간할당.
3. OS 상에서 프로세스시작 -> 사용자 요청 받을 수 있게 됨

- 프로세스 및 스레드는 프로그램 실행파일 자체가 아님.
- OS 상에서 독립성 가지고 동작하는 것.
- 프로세스는 실행시 독자 메모리 공간을 점유하며, 프로세스 안에서 스레드들이 실행 됨. 한 프로세스 안에서 실행되는 스레드 들은 메모리 공간을 공유
  -> 프로세스 실행시 커널에 의해 메모리공간이 확보 됨

#### 프로세스 스레드 선택기준

애플리케이션 목적에 따라 프로세스와 스레드 특성을 생각해 개발자가 정함.

- 프로세스:
  장점: 개별처리 독립성이 높다.
  단점 : 메모리 공간 할당하므로 프로세스 생성시 CPU부하가 스레드보다 높음  
  -> 멀티 프로세스 애플리케이션에서는 프로세스 생성 부담 낮추기 위해 미리 프로세스 시작해 둠 (연결 풀링)

##### Memo

프로세스도 독자 메모리 영역 가진 상태로 프로세스간 메모리공간을 공유하는 형태를 취하는게 가능하긴 함  
ex)  
프로세스 간 공유하고 싶은 캐시로 저장하는 데이터는 공유공간에  
프로세스 단독으로 이용하는 데이터, 자신이 계산한 데이터는 전용 메모리에 둔다.

- 스레드:  
  장점: 생성시 부하가 낮다  
  단점: 메모리 공간 공유해 의도치 않은 데이터 읽기/쓰기 발생할 수 있음.  
  ->스레드세이프 이슈

ex)  
생활비 통장을 사용하는 가족에 비유해보면  
프로세스: 맞벌이 부부처럼 생활비 통장을 각자 관리  
쓰레드: 통장한개로 아내가 남편의 부양가족 되는느낌, 부양가족이 늘어나도(쓰래드가 늘어나도) 통장한개로 생활한다

### 3.2.2 OS 커널

- OS에서 커널은 심장이자 뇌이며 척수. ->OS의 본질이며 나머지는 덤
- 커널 덕분에 개발자는 하드웨어나 다른 애플리케이션에 미치는 영향 의식하지 않고 개발 가능.
- OS처리는 원칙적으로 커널 통해 이뤄짐

#### 커널의 역할 6가지

1. 시스템 콜 인터페이스: 프로세스나 스레드로부터 명령 받는 인터페이스 + 입력장치(키보드, 마우스)입력 (inturupt)

2. 프로세스 관리: 가동되고 있는 프로세스 관리와 CPU이용 우선순위 등 스케줄

3. 메모리 관리: 서버 상의 메모리를 단위크기(예를들어 4kb)블록으로 분할해서 프로세스에 할당

4. 네트워크 스택: 네트워크 관리
5. 파일 시스템 관리
6. 장치 드라이버: 디스크, HBA 등 물리 장치와 작업

#### 1. 시스템 콜 인터페이스

프로세스/ 스레드에서 커널로 연결되는 인터페이스.
애플리케이션이 OS서 어떤 처리를 하고 싶으면 시스템 콜이라고 하는 명령 이용해서 커널에 명령 내림.  
이때 명령이 인터페이스를 통해 전달됨-> 은행이나 구청 접수창구 같은 역할  
ex) 프로세스들은 디스크I/O, 네트워크I/O or 새로운 프로세스 생성시 시스템콜호출해서 커널에 명령 내림  
-> 프로세스의 관점에서는 디스크I/O, 네트워크I/O는 동일한 시스템콜이라는 점에서 차이가 없다.

#### 2. 프로세스 관리(OS에 있어 가장 중요한 기능)

OS상에서는 수십, 수백, 수천개의 프로세스를 가동할 수 있다.  
But, 물리서버의 CPU 코어 수는 많아야 수십개  
언제 어떤 프로세스가 어느정도의 CPU코어를 이용 가능한지, 처리순서는 어쩔지 관리하는 것이 이 기능의 역할.

#### 3. 메모리 관리

메모리 영역을 관리한다. 프로세스 관리는 CPU관리했지만 메모리 관리에서는 물리 메모리 공간의 최대치를 고려함.  
프로세스가 이용하는 독립메모리 공간 확보 or 상호간 참조 영역 지키기 위해 독립성 관리.  
이 기능이 없으면 각 프로세스는 자신 이외의 프로세스가 사용하고 있는 메모리 영역을 일일이 파악해야 하므로 애플리케이션 개발이 매우 어려워진다.

#### 5. 파일 시스템 관리

파일시스템용 인터페이스관리.
파일 시스템은 OS 기능의 하나로서 물리 디스크에 제공된 데이터 관리하는 기능  
각종 파일들의 데이터는 디스크상에서 구분표시도 없이 '010110'과 같은 숫자집합에 불과함.  
->파일시스템 덕분에 애플리케이션은 '파일', '디렉토리'단위로 데이터 작성 삭제 가능

- 프로세스(스레드)는 편리성 때문에 모든 것을 파일단위로 생각함
  -> 커널에서 파일시스템의 인터페이스로 동작해주기 때문에 가능  
  -> 덕분에 프로세스는 물리디스크 구조나 데이터 배치 상태를 고려할 필요가 없다
- 파일시스템은 여러 프로세스가 공유한다.

#### 6. 장치 드라이버

디스크나 NIC(Network Interface card 렌카드) 등 물리장치용 인터페이스 제공.  
다양한 장치들은 각 제조사별로 OS에 대응하는 드라이버를 준비해 커널을 통해 애플리케이션에 일관된 인터페이스를 제공한다(커널의 인터페이스를 통해 각 물리장치를 은폐)  
-> 이렇게 되지 않으면 각 장치별로 장치의 인터페이스에 맞는 애플리케이션을 개발해야함

#### 커널은 결코 견고하지 않다.

커널 설계 및 구현방식은 크게 두가지

1. 모놀리식(단일형) 커널:

- OS의 주요 구성요소 모두 하나의 메모리공간을 통해 제공  
  대표 예시) 유닉스계열의 OS, 리눅스

2. 마이크로(작다) 커널

- 최소한의 기능만 커널이 제공하고 그 외 기능은 커널 밖에서 제공(더 심플한 형태의 커널)  
  대표 예시) 애플이 MAC OS

대부분의 아키텍쳐는 양쪽의 장점을 취하고있다.

## 3.3 웹데이터 흐름

### 3.3.1 클라이언트 PC부터 웹 서버(프레젠테이션 계층)까지

PC에서 웹프라우저 실행해서 웹서버에 요청을 보내고 AP서버로 질의하기까지 흐름

\<PC>

1. OS상에서 브라우저 실행
2. 커널경유해서 디스크에있는 브라우저 응용프로그램 읽어서 메모리에 상주시켜 브라우저 프로세스 실행
3. 브라우저에서 주소창에 주소질의
4. 질의는 OS의 시스탬콜로 실행되고 커널을 경유해 NIC(Network Interface card 렌카드)에 네트워크 통신 요청됨
5. 네트워크 경유로 웹서버에 질의

\<이름 해석 name resolution>  
http://jpub.kr질의했다고 치면

- 웹브라우저는 jpub.kr 의 IP주소 알 수 없음.

1. OS의 호스트명, IP주소 변환 테이블을 참조해서 존재하지 않는 경우 외부의 DNS서버에 요청을 던진다.
2. DNS서버에 호스트명이 아닌 IP주소로 지정돼 있는 것은 이때문
3. 전세계 DNS서버는 Root DNS기준으로 트리구조로 돼있음.  
   -> 개별 DNS서버는 정기적으로 부모 DNS서버에서 데이터 받아 최신 IP주소 목록 유지

\<웹서버>(프레젠테이션 계층)

- 웹서버의 역할은 HTTP(HyperText Transfer Protocol)요청에 대해 적절한 파일이나 콘텐츠 반환하는 것  
  -> 텍스트 송수신 위한 약속. 기본 텍스트 데이터에 대한 프로토콜이지만 동영상이나 데이터의 바이너리 데이터 전송에도 이용되고 있음.
- 웹서버 Apache Http Server, ngnix 등등

1. 해당사이트가 어디에 있는지 이름 해석해 해당하는 웹서버에 요청이 전송
2. 웹서버의 'httpd'프로세스가 정적 콘텐츠(디스크에서 읽을지)인지 동적 콘텐츠(AP서버에 질의할지) 판단.  
   2-1. 디스크 내부에 있는정보->시스템콜실행->커널통해 디스크에서 파일 읽어와 응답  
   2-2. AP서버 질의->시스템콜 실행->커널통해 NIC(Network Interface card 렌카드)에 대한 네트워크 통신 요청->스위치 경유해서 AP서버에 질의가 이뤄짐

### 3.3.2 웹서버부터 AP서버까지

'동적콘텐츠'에 대한 요청 처리하는 것이 AP서버.

1. 웹서버에서 온 요청-> AP서버의 NIC경유해서 커널에 의해 끼어들기처리 (inturrupt: 입력장치 입력도 inturrupt라고 함)
2. AP서버의 OS의 JVM상에 돌아가는 스레드가 요청 접수.  
   2-1. 자신이 계산한값은 그대로 리스폰스  
   2-2. DB질의 필요한 부분은 여기서 대기

3. DB접속은 드라이버를 통해서 연결 풀(connection pool)로 관리 됨.

4. DB에 대한 접속 요청은 OS의 시스템콜로 실행되고, 커널통해 NIC에 대한 네트워크 통신 이뤄짐.
5. 네트워크 경유로 DB서버에 대한 질의 이뤄짐
   ->이때 AP서버가 DB서버에 접속하려면 '드라이버'필요(커널의 장치드라이버랑 비슷)  
   ->즉, 드라이버 뒷단에 있는 것이 데이터베이스로 가는 인터페이스로 해당 데이터베이스 자체를 은폐하는 역할 함.

#### MEMO 자바가상머신 JVM은 하나의 거대한 프로세스

가상머신이므로 하나의 OS로서 다양한 기능을 가지고 있다.  
->즉 다양한 역할을 하는 복수의 스레드를 갖는다.  
ex)  
사용자 잔금 정보를 요청받았지만 AP서버에 정보는 없다.  
->AP서버의 스레드 DB서버에 질의  
->돌아온 결과를 HTML등으로 정리해서 반환

#### MEMO 캐시서버와 CDN

데이터 필요시 무조건 DB에 접속하는 것이 효율적인건 아니다.  
규모가 작고 갱신 빈도가 낮은 정보(정적 데이터)를 매번 데이터베이스에 질의는 비효율적

- 대안  
  방법1: JVM내부에 캐시로 저장해 두었다가 반환
  방법2: DB서버보다 빠른 '캐시전용서버'만들어 그쪽에 질의
  방법3: 규모가 큰 정적 데이터 전송시 CDN(Content Delivery Network 데이터전송서버)사용  
  ->대부분의 웹 시스템 CDN 사용.  
  ->대량의 데이터 전송에 특화된 것으로 전 세계에 있는 데이터 복사본(캐시)을 배치하는 기술과 병렬 기술 활용해서 처리를 효율화 하고있다.  
  But  
  ->기업형 시스템에서는 CDN 잘 사용되지 않음.
  ->하나의 시스템에 대한 사용자수 제한되 있고, 데이터를 갱신하는 작업이 많기 때문

### 3.3.3 AP서버부터 DB서버까지

DB서버는 SQL해석해 데이터 엑세스 방식 정하고, 디스크나 메모리(공유메모리 영역에 캐시된 데이터 or in-memory DB)에서 필요한 데이터 수집.
-> 속도는 당연히 디스크에서 읽어오는게 느리다.

AP서버로부터 요청이 도착하면,

1. DB프로세스가 요청 접수
2. 이전 사용한 정보는 캐시에 저장하는 구조라 캐시데이터부터 확인하기 위해, 일단 공유메모리영역 검색
3. 공유메모리에 데이터 없을 시 디스크에서 읽는다.
   -> DB프로세스-> 시스템콜 실행 -> 커널경유->디스크 읽어 옴  
   (많은 경우 DB서버 내부에 디스크가 있는게 아닌 대량 데이터 고속 액세스 위한 저장장치전용 서버를 따로 둬 외부의 디스크를 읽어오게 함)

4. 한번 액세스한 데이터는 메모리에 캐시 형태로 저장, 이후 액세스시 재사용
5. AP서버에 결과 반환.

#### MEMO RDBMS와 KVS(Key Value Store)

RDBMS:

1. 표(테이블)로 데이터 표현해 필연적으로 데이터 정리된다.
2. 릴레이션에 의해 테이블 간 관계 표현 (정돈된 형태)

KVS:

1. 데이터 자유로운 형태로 저장가능
2. 여러대 서버에 수평 분할(sharding 샤딩)하기 쉽다  
   -> 단, 자유도 높은 만큼 복잡성이 커져 관리 어렵다.

### 3.3.4 AP서버부터 웹까지
